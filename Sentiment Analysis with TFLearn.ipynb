{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis with TFLearn\n",
    "\n",
    "In this notebook, we'll continue Andrew Trask's work by building a network for sentiment analysis on the movie review data. Instead of a network written with Numpy, we'll be using [TFLearn](http://tflearn.org/), a high-level library built on top of TensorFlow. TFLearn makes it simpler to build networks just by defining the layers. It takes care of most of the details for you.\n",
    "\n",
    "We'll start off by importing all the modules we'll need, then load and prepare the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tflearn\n",
    "from tflearn.data_utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data\n",
    "\n",
    "Following along with Andrew, our goal here is to convert our reviews into word vectors. The word vectors will have elements representing words in the total vocabulary. If the second position represents the word 'the', for each review we'll count up the number of times 'the' appears in the text and set the second position to that count. I'll show you examples as we build the input data from the reviews data. Check out Andrew's notebook and video for more about this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data\n",
    "\n",
    "Use the pandas library to read the reviews and postive/negative labels from comma-separated files. The data we're using has already been preprocessed a bit and we know it uses only lower case characters. If we were working from raw data, where we didn't know it was all lower case, we would want to add a step here to convert it. That's so we treat different variations of the same word, like `The`, `the`, and `THE`, all the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reviews = pd.read_csv('reviews.txt', header=None)\n",
    "labels = pd.read_csv('labels.txt', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting word frequency\n",
    "\n",
    "To start off we'll need to count how often each word appears in the data. We'll use this count to create a vocabulary we'll use to encode the review data. This resulting count is known as a [bag of words](https://en.wikipedia.org/wiki/Bag-of-words_model). We'll use it to select our vocabulary and build the word vectors. You should have seen how to do this in Andrew's lesson. Try to implement it here using the [Counter class](https://docs.python.org/2/library/collections.html#collections.Counter).\n",
    "\n",
    "> **Exercise:** Create the bag of words from the reviews data and assign it to `total_counts`. The reviews are stores in the `reviews` [Pandas DataFrame](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html). If you want the reviews as a Numpy array, use `reviews.values`. You can iterate through the rows in the DataFrame with `for idx, row in reviews.iterrows():` ([documentation](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.iterrows.html)). When you break up the reviews into words, use `.split(' ')` instead of `.split()` so your results match ours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words in data set:  74074\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "total_counts = Counter()\n",
    "for idx,row in reviews.iterrows():\n",
    "            for word in row[0].split(' '):\n",
    "                total_counts[word] += 1 # bag of words here\n",
    "\n",
    "print(\"Total words in data set: \", len(total_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 1111930),\n",
       " ('the', 336713),\n",
       " ('.', 327192),\n",
       " ('and', 164107),\n",
       " ('a', 163009),\n",
       " ('of', 145864),\n",
       " ('to', 135720),\n",
       " ('is', 107328),\n",
       " ('br', 101872),\n",
       " ('it', 96352),\n",
       " ('in', 93968),\n",
       " ('i', 87623),\n",
       " ('this', 76000),\n",
       " ('that', 73245),\n",
       " ('s', 65361),\n",
       " ('was', 48208),\n",
       " ('as', 46933),\n",
       " ('for', 44343),\n",
       " ('with', 44125),\n",
       " ('movie', 44039),\n",
       " ('but', 42603),\n",
       " ('film', 40155),\n",
       " ('you', 34230),\n",
       " ('on', 34200),\n",
       " ('t', 34081),\n",
       " ('not', 30626),\n",
       " ('he', 30138),\n",
       " ('are', 29430),\n",
       " ('his', 29374),\n",
       " ('have', 27731),\n",
       " ('be', 26957),\n",
       " ('one', 26789),\n",
       " ('all', 23978),\n",
       " ('at', 23513),\n",
       " ('they', 22906),\n",
       " ('by', 22546),\n",
       " ('an', 21560),\n",
       " ('who', 21433),\n",
       " ('so', 20617),\n",
       " ('from', 20498),\n",
       " ('like', 20276),\n",
       " ('there', 18832),\n",
       " ('her', 18421),\n",
       " ('or', 18004),\n",
       " ('just', 17771),\n",
       " ('about', 17374),\n",
       " ('out', 17113),\n",
       " ('if', 16803),\n",
       " ('has', 16790),\n",
       " ('what', 16159),\n",
       " ('some', 15747),\n",
       " ('good', 15143),\n",
       " ('can', 14654),\n",
       " ('more', 14251),\n",
       " ('she', 14223),\n",
       " ('when', 14182),\n",
       " ('very', 14069),\n",
       " ('up', 13291),\n",
       " ('time', 12724),\n",
       " ('no', 12717),\n",
       " ('even', 12651),\n",
       " ('my', 12503),\n",
       " ('would', 12436),\n",
       " ('which', 12047),\n",
       " ('story', 11988),\n",
       " ('only', 11918),\n",
       " ('really', 11738),\n",
       " ('see', 11478),\n",
       " ('their', 11385),\n",
       " ('had', 11290),\n",
       " ('we', 10859),\n",
       " ('were', 10783),\n",
       " ('me', 10773),\n",
       " ('well', 10659),\n",
       " ('than', 9919),\n",
       " ('much', 9763),\n",
       " ('get', 9309),\n",
       " ('bad', 9308),\n",
       " ('been', 9289),\n",
       " ('people', 9285),\n",
       " ('will', 9211),\n",
       " ('do', 9177),\n",
       " ('other', 9163),\n",
       " ('also', 9158),\n",
       " ('into', 9111),\n",
       " ('first', 9061),\n",
       " ('great', 9059),\n",
       " ('because', 9045),\n",
       " ('how', 8901),\n",
       " ('him', 8876),\n",
       " ('don', 8804),\n",
       " ('most', 8783),\n",
       " ('made', 8364),\n",
       " ('its', 8277),\n",
       " ('then', 8119),\n",
       " ('make', 8025),\n",
       " ('way', 8025),\n",
       " ('them', 7970),\n",
       " ('could', 7923),\n",
       " ('too', 7833),\n",
       " ('movies', 7666),\n",
       " ('any', 7660),\n",
       " ('after', 7638),\n",
       " ('think', 7298),\n",
       " ('characters', 7160),\n",
       " ('character', 7020),\n",
       " ('watch', 6974),\n",
       " ('two', 6906),\n",
       " ('films', 6890),\n",
       " ('seen', 6679),\n",
       " ('many', 6675),\n",
       " ('life', 6628),\n",
       " ('being', 6610),\n",
       " ('plot', 6586),\n",
       " ('acting', 6493),\n",
       " ('never', 6485),\n",
       " ('love', 6453),\n",
       " ('little', 6437),\n",
       " ('best', 6413),\n",
       " ('where', 6392),\n",
       " ('over', 6333),\n",
       " ('did', 6296),\n",
       " ('show', 6294),\n",
       " ('know', 6167),\n",
       " ('off', 6030),\n",
       " ('ever', 5997),\n",
       " ('man', 5976),\n",
       " ('does', 5940),\n",
       " ('here', 5767),\n",
       " ('better', 5739),\n",
       " ('your', 5686),\n",
       " ('end', 5650),\n",
       " ('still', 5623),\n",
       " ('these', 5418),\n",
       " ('say', 5396),\n",
       " ('scene', 5383),\n",
       " ('why', 5318),\n",
       " ('while', 5317),\n",
       " ('scenes', 5212),\n",
       " ('go', 5157),\n",
       " ('ve', 5136),\n",
       " ('such', 5134),\n",
       " ('something', 5077),\n",
       " ('should', 5041),\n",
       " ('m', 4998),\n",
       " ('back', 4971),\n",
       " ('through', 4969),\n",
       " ('real', 4738),\n",
       " ('those', 4697),\n",
       " ('watching', 4606),\n",
       " ('now', 4605),\n",
       " ('though', 4566),\n",
       " ('doesn', 4536),\n",
       " ('thing', 4528),\n",
       " ('old', 4526),\n",
       " ('years', 4517),\n",
       " ('re', 4504),\n",
       " ('actors', 4484),\n",
       " ('director', 4445),\n",
       " ('work', 4373),\n",
       " ('another', 4329),\n",
       " ('before', 4324),\n",
       " ('didn', 4318),\n",
       " ('new', 4312),\n",
       " ('nothing', 4290),\n",
       " ('funny', 4289),\n",
       " ('actually', 4239),\n",
       " ('makes', 4204),\n",
       " ('look', 4147),\n",
       " ('find', 4132),\n",
       " ('going', 4102),\n",
       " ('few', 4076),\n",
       " ('same', 4053),\n",
       " ('part', 4040),\n",
       " ('again', 4007),\n",
       " ('lot', 3979),\n",
       " ('every', 3979),\n",
       " ('world', 3833),\n",
       " ('cast', 3827),\n",
       " ('us', 3790),\n",
       " ('quite', 3739),\n",
       " ('down', 3728),\n",
       " ('want', 3703),\n",
       " ('things', 3688),\n",
       " ('pretty', 3664),\n",
       " ('young', 3660),\n",
       " ('seems', 3619),\n",
       " ('around', 3617),\n",
       " ('horror', 3591),\n",
       " ('got', 3587),\n",
       " ('however', 3535),\n",
       " ('fact', 3523),\n",
       " ('take', 3509),\n",
       " ('big', 3477),\n",
       " ('enough', 3452),\n",
       " ('long', 3451),\n",
       " ('thought', 3437),\n",
       " ('series', 3416),\n",
       " ('both', 3406),\n",
       " ('between', 3390),\n",
       " ('may', 3387),\n",
       " ('give', 3376),\n",
       " ('original', 3376),\n",
       " ('action', 3355),\n",
       " ('own', 3349),\n",
       " ('right', 3313),\n",
       " ('without', 3266),\n",
       " ('must', 3250),\n",
       " ('comedy', 3246),\n",
       " ('always', 3239),\n",
       " ('times', 3238),\n",
       " ('point', 3224),\n",
       " ('gets', 3204),\n",
       " ('family', 3202),\n",
       " ('role', 3189),\n",
       " ('come', 3189),\n",
       " ('isn', 3177),\n",
       " ('saw', 3167),\n",
       " ('almost', 3140),\n",
       " ('interesting', 3129),\n",
       " ('least', 3113),\n",
       " ('done', 3096),\n",
       " ('whole', 3078),\n",
       " ('d', 3077),\n",
       " ('bit', 3055),\n",
       " ('music', 3054),\n",
       " ('guy', 3035),\n",
       " ('script', 3028),\n",
       " ('far', 2977),\n",
       " ('making', 2960),\n",
       " ('minutes', 2953),\n",
       " ('feel', 2951),\n",
       " ('anything', 2949),\n",
       " ('last', 2933),\n",
       " ('might', 2918),\n",
       " ('since', 2907),\n",
       " ('performance', 2896),\n",
       " ('ll', 2893),\n",
       " ('girl', 2853),\n",
       " ('probably', 2842),\n",
       " ('am', 2807),\n",
       " ('woman', 2795),\n",
       " ('kind', 2783),\n",
       " ('tv', 2782),\n",
       " ('away', 2775),\n",
       " ('yet', 2752),\n",
       " ('day', 2746),\n",
       " ('rather', 2734),\n",
       " ('worst', 2732),\n",
       " ('fun', 2693),\n",
       " ('sure', 2686),\n",
       " ('hard', 2668),\n",
       " ('anyone', 2632),\n",
       " ('played', 2588),\n",
       " ('each', 2580),\n",
       " ('found', 2573),\n",
       " ('having', 2546),\n",
       " ('although', 2537),\n",
       " ('especially', 2535),\n",
       " ('our', 2510),\n",
       " ('course', 2506),\n",
       " ('believe', 2505),\n",
       " ('screen', 2493),\n",
       " ('comes', 2484),\n",
       " ('looking', 2483),\n",
       " ('trying', 2473),\n",
       " ('set', 2454),\n",
       " ('goes', 2442),\n",
       " ('book', 2420),\n",
       " ('looks', 2413),\n",
       " ('place', 2411),\n",
       " ('actor', 2388),\n",
       " ('different', 2382),\n",
       " ('put', 2381),\n",
       " ('year', 2361),\n",
       " ('money', 2361),\n",
       " ('ending', 2357),\n",
       " ('dvd', 2345),\n",
       " ('maybe', 2341),\n",
       " ('let', 2339),\n",
       " ('someone', 2337),\n",
       " ('true', 2333),\n",
       " ('once', 2329),\n",
       " ('sense', 2326),\n",
       " ('everything', 2325),\n",
       " ('reason', 2323),\n",
       " ('wasn', 2308),\n",
       " ('shows', 2307),\n",
       " ('three', 2295),\n",
       " ('worth', 2278),\n",
       " ('job', 2277),\n",
       " ('main', 2264),\n",
       " ('together', 2243),\n",
       " ('play', 2238),\n",
       " ('watched', 2236),\n",
       " ('american', 2228),\n",
       " ('everyone', 2223),\n",
       " ('plays', 2213),\n",
       " ('john', 2208),\n",
       " ('effects', 2204),\n",
       " ('later', 2199),\n",
       " ('audience', 2198),\n",
       " ('said', 2196),\n",
       " ('takes', 2192),\n",
       " ('instead', 2190),\n",
       " ('house', 2185),\n",
       " ('beautiful', 2176),\n",
       " ('seem', 2175),\n",
       " ('night', 2165),\n",
       " ('high', 2161),\n",
       " ('himself', 2159),\n",
       " ('version', 2157),\n",
       " ('wife', 2140),\n",
       " ('during', 2130),\n",
       " ('left', 2125),\n",
       " ('father', 2121),\n",
       " ('special', 2113),\n",
       " ('seeing', 2099),\n",
       " ('half', 2094),\n",
       " ('star', 2083),\n",
       " ('excellent', 2071),\n",
       " ('shot', 2051),\n",
       " ('war', 2051),\n",
       " ('idea', 2043),\n",
       " ('black', 2034),\n",
       " ('nice', 2012),\n",
       " ('less', 2001),\n",
       " ('else', 2000),\n",
       " ('mind', 1995),\n",
       " ('simply', 1965),\n",
       " ('read', 1964),\n",
       " ('second', 1962),\n",
       " ('fan', 1911),\n",
       " ('men', 1909),\n",
       " ('death', 1907),\n",
       " ('hollywood', 1906),\n",
       " ('poor', 1897),\n",
       " ('help', 1896),\n",
       " ('completely', 1889),\n",
       " ('used', 1879),\n",
       " ('home', 1877),\n",
       " ('dead', 1877),\n",
       " ('line', 1868),\n",
       " ('short', 1866),\n",
       " ('either', 1866),\n",
       " ('top', 1848),\n",
       " ('given', 1848),\n",
       " ('kids', 1843),\n",
       " ('budget', 1836),\n",
       " ('try', 1831),\n",
       " ('classic', 1829),\n",
       " ('wrong', 1823),\n",
       " ('performances', 1821),\n",
       " ('women', 1816),\n",
       " ('enjoy', 1812),\n",
       " ('boring', 1811),\n",
       " ('need', 1807),\n",
       " ('use', 1804),\n",
       " ('rest', 1803),\n",
       " ('low', 1799),\n",
       " ('friends', 1791),\n",
       " ('production', 1790),\n",
       " ('full', 1779),\n",
       " ('camera', 1777),\n",
       " ('until', 1776),\n",
       " ('along', 1775),\n",
       " ('truly', 1743),\n",
       " ('video', 1731),\n",
       " ('awful', 1725),\n",
       " ('tell', 1718),\n",
       " ('couple', 1718),\n",
       " ('next', 1717),\n",
       " ('remember', 1702),\n",
       " ('stupid', 1701),\n",
       " ('start', 1700),\n",
       " ('stars', 1697),\n",
       " ('sex', 1684),\n",
       " ('perhaps', 1684),\n",
       " ('mean', 1683),\n",
       " ('won', 1679),\n",
       " ('came', 1673),\n",
       " ('recommend', 1668),\n",
       " ('moments', 1665),\n",
       " ('school', 1659),\n",
       " ('episode', 1658),\n",
       " ('wonderful', 1658),\n",
       " ('small', 1646),\n",
       " ('face', 1645),\n",
       " ('understand', 1644),\n",
       " ('terrible', 1638),\n",
       " ('playing', 1633),\n",
       " ('getting', 1627),\n",
       " ('written', 1616),\n",
       " ('early', 1605),\n",
       " ('name', 1604),\n",
       " ('doing', 1603),\n",
       " ('keep', 1601),\n",
       " ('style', 1601),\n",
       " ('often', 1601),\n",
       " ('perfect', 1598),\n",
       " ('human', 1596),\n",
       " ('person', 1595),\n",
       " ('others', 1595),\n",
       " ('definitely', 1580),\n",
       " ('gives', 1577),\n",
       " ('itself', 1562),\n",
       " ('boy', 1560),\n",
       " ('lines', 1553),\n",
       " ('lost', 1552),\n",
       " ('live', 1552),\n",
       " ('become', 1543),\n",
       " ('dialogue', 1542),\n",
       " ('head', 1541),\n",
       " ('piece', 1537),\n",
       " ('finally', 1536),\n",
       " ('case', 1533),\n",
       " ('yes', 1532),\n",
       " ('felt', 1528),\n",
       " ('mother', 1523),\n",
       " ('supposed', 1516),\n",
       " ('liked', 1516),\n",
       " ('children', 1509),\n",
       " ('title', 1497),\n",
       " ('couldn', 1493),\n",
       " ('cinema', 1493),\n",
       " ('white', 1491),\n",
       " ('absolutely', 1485),\n",
       " ('picture', 1484),\n",
       " ('against', 1477),\n",
       " ('sort', 1472),\n",
       " ('worse', 1469),\n",
       " ('went', 1463),\n",
       " ('certainly', 1463),\n",
       " ('entire', 1461),\n",
       " ('waste', 1457),\n",
       " ('killer', 1455),\n",
       " ('problem', 1450),\n",
       " ('oh', 1449),\n",
       " ('mr', 1448),\n",
       " ('hope', 1447),\n",
       " ('evil', 1446),\n",
       " ('entertaining', 1443),\n",
       " ('friend', 1442),\n",
       " ('overall', 1437),\n",
       " ('called', 1433),\n",
       " ('based', 1431),\n",
       " ('loved', 1428),\n",
       " ('fans', 1421),\n",
       " ('several', 1420),\n",
       " ('drama', 1411),\n",
       " ('beginning', 1401),\n",
       " ('lives', 1393),\n",
       " ('direction', 1385),\n",
       " ('care', 1385),\n",
       " ('already', 1381),\n",
       " ('dark', 1381),\n",
       " ('becomes', 1380),\n",
       " ('laugh', 1375),\n",
       " ('example', 1371),\n",
       " ('under', 1368),\n",
       " ('despite', 1364),\n",
       " ('seemed', 1363),\n",
       " ('throughout', 1361),\n",
       " ('turn', 1359),\n",
       " ('son', 1356),\n",
       " ('unfortunately', 1353),\n",
       " ('wanted', 1352),\n",
       " ('michael', 1333),\n",
       " ('history', 1331),\n",
       " ('heart', 1328),\n",
       " ('final', 1327),\n",
       " ('fine', 1324),\n",
       " ('child', 1324),\n",
       " ('sound', 1320),\n",
       " ('amazing', 1320),\n",
       " ('guess', 1311),\n",
       " ('lead', 1310),\n",
       " ('humor', 1309),\n",
       " ('totally', 1307),\n",
       " ('writing', 1304),\n",
       " ('guys', 1303),\n",
       " ('quality', 1301),\n",
       " ('close', 1296),\n",
       " ('art', 1289),\n",
       " ('wants', 1288),\n",
       " ('game', 1283),\n",
       " ('behind', 1279),\n",
       " ('works', 1279),\n",
       " ('town', 1278),\n",
       " ('side', 1276),\n",
       " ('tries', 1274),\n",
       " ('days', 1268),\n",
       " ('past', 1263),\n",
       " ('viewer', 1262),\n",
       " ('able', 1259),\n",
       " ('flick', 1258),\n",
       " ('hand', 1257),\n",
       " ('genre', 1255),\n",
       " ('turns', 1251),\n",
       " ('act', 1251),\n",
       " ('enjoyed', 1246),\n",
       " ('today', 1245),\n",
       " ('kill', 1234),\n",
       " ('favorite', 1232),\n",
       " ('car', 1224),\n",
       " ('soon', 1223),\n",
       " ('starts', 1220),\n",
       " ('run', 1219),\n",
       " ('actress', 1219),\n",
       " ('sometimes', 1218),\n",
       " ('gave', 1217),\n",
       " ('eyes', 1217),\n",
       " ('b', 1212),\n",
       " ('girls', 1211),\n",
       " ('late', 1211),\n",
       " ('etc', 1210),\n",
       " ('god', 1208),\n",
       " ('directed', 1204),\n",
       " ('horrible', 1201),\n",
       " ('kid', 1200),\n",
       " ('city', 1197),\n",
       " ('brilliant', 1196),\n",
       " ('parts', 1191),\n",
       " ('hour', 1187),\n",
       " ('blood', 1186),\n",
       " ('self', 1185),\n",
       " ('themselves', 1184),\n",
       " ('stories', 1180),\n",
       " ('thinking', 1179),\n",
       " ('expect', 1178),\n",
       " ('stuff', 1174),\n",
       " ('obviously', 1163),\n",
       " ('decent', 1157),\n",
       " ('voice', 1156),\n",
       " ('writer', 1152),\n",
       " ('highly', 1148),\n",
       " ('fight', 1148),\n",
       " ('myself', 1147),\n",
       " ('feeling', 1145),\n",
       " ('daughter', 1138),\n",
       " ('slow', 1132),\n",
       " ('except', 1130),\n",
       " ('matter', 1127),\n",
       " ('type', 1125),\n",
       " ('age', 1119),\n",
       " ('anyway', 1117),\n",
       " ('roles', 1113),\n",
       " ('moment', 1112),\n",
       " ('killed', 1111),\n",
       " ('heard', 1111),\n",
       " ('says', 1110),\n",
       " ('leave', 1106),\n",
       " ('brother', 1105),\n",
       " ('took', 1100),\n",
       " ('strong', 1098),\n",
       " ('cannot', 1097),\n",
       " ('police', 1097),\n",
       " ('violence', 1092),\n",
       " ('hit', 1087),\n",
       " ('stop', 1084),\n",
       " ('happens', 1081),\n",
       " ('known', 1079),\n",
       " ('particularly', 1078),\n",
       " ('involved', 1077),\n",
       " ('happened', 1076),\n",
       " ('extremely', 1069),\n",
       " ('chance', 1069),\n",
       " ('james', 1068),\n",
       " ('obvious', 1066),\n",
       " ('told', 1063),\n",
       " ('murder', 1063),\n",
       " ('living', 1063),\n",
       " ('coming', 1062),\n",
       " ('alone', 1061),\n",
       " ('experience', 1059),\n",
       " ('lack', 1058),\n",
       " ('hero', 1055),\n",
       " ('wouldn', 1054),\n",
       " ('including', 1052),\n",
       " ('attempt', 1050),\n",
       " ('please', 1047),\n",
       " ('happen', 1044),\n",
       " ('gore', 1043),\n",
       " ('crap', 1039),\n",
       " ('wonder', 1038),\n",
       " ('cut', 1035),\n",
       " ('group', 1034),\n",
       " ('complete', 1034),\n",
       " ('ago', 1033),\n",
       " ('interest', 1033),\n",
       " ('score', 1030),\n",
       " ('none', 1030),\n",
       " ('husband', 1026),\n",
       " ('save', 1023),\n",
       " ('hell', 1023),\n",
       " ('david', 1023),\n",
       " ('simple', 1022),\n",
       " ('ok', 1018),\n",
       " ('looked', 1010),\n",
       " ('song', 1008),\n",
       " ('career', 1007),\n",
       " ('number', 1006),\n",
       " ('seriously', 1001),\n",
       " ('possible', 1000),\n",
       " ('annoying', 998),\n",
       " ('sad', 996),\n",
       " ('exactly', 995),\n",
       " ('shown', 994),\n",
       " ('king', 993),\n",
       " ('musical', 992),\n",
       " ('running', 992),\n",
       " ('serious', 989),\n",
       " ('yourself', 989),\n",
       " ('scary', 988),\n",
       " ('taken', 987),\n",
       " ('reality', 987),\n",
       " ('released', 986),\n",
       " ('whose', 986),\n",
       " ('cinematography', 985),\n",
       " ('english', 985),\n",
       " ('ends', 984),\n",
       " ('hours', 983),\n",
       " ('usually', 981),\n",
       " ('opening', 979),\n",
       " ('jokes', 976),\n",
       " ('light', 976),\n",
       " ('hilarious', 972),\n",
       " ('cool', 971),\n",
       " ('across', 971),\n",
       " ('body', 970),\n",
       " ('somewhat', 966),\n",
       " ('happy', 965),\n",
       " ('relationship', 965),\n",
       " ('usual', 965),\n",
       " ('ridiculous', 965),\n",
       " ('view', 964),\n",
       " ('started', 963),\n",
       " ('level', 963),\n",
       " ('change', 961),\n",
       " ('opinion', 959),\n",
       " ('novel', 957),\n",
       " ('wish', 957),\n",
       " ('middle', 956),\n",
       " ('talking', 955),\n",
       " ('taking', 955),\n",
       " ('documentary', 953),\n",
       " ('ones', 952),\n",
       " ('robert', 951),\n",
       " ('order', 949),\n",
       " ('finds', 948),\n",
       " ('shots', 948),\n",
       " ('power', 947),\n",
       " ('female', 946),\n",
       " ('saying', 946),\n",
       " ('huge', 945),\n",
       " ('room', 944),\n",
       " ('mostly', 940),\n",
       " ('episodes', 939),\n",
       " ('country', 934),\n",
       " ('talent', 933),\n",
       " ('five', 933),\n",
       " ('important', 931),\n",
       " ('rating', 930),\n",
       " ('modern', 929),\n",
       " ('earth', 928),\n",
       " ('word', 927),\n",
       " ('major', 927),\n",
       " ('strange', 927),\n",
       " ('turned', 925),\n",
       " ('call', 923),\n",
       " ('jack', 922),\n",
       " ('apparently', 918),\n",
       " ('single', 918),\n",
       " ('disappointed', 917),\n",
       " ('events', 911),\n",
       " ('four', 911),\n",
       " ('due', 909),\n",
       " ('songs', 908),\n",
       " ('basically', 906),\n",
       " ('attention', 905),\n",
       " ('television', 903),\n",
       " ('comic', 901),\n",
       " ('knows', 901),\n",
       " ('supporting', 899),\n",
       " ('future', 899),\n",
       " ('clearly', 899),\n",
       " ('non', 899),\n",
       " ('british', 898),\n",
       " ('knew', 898),\n",
       " ('paul', 897),\n",
       " ('thriller', 897),\n",
       " ('fast', 897),\n",
       " ('class', 893),\n",
       " ('easily', 892),\n",
       " ('cheap', 892),\n",
       " ('silly', 889),\n",
       " ('problems', 887),\n",
       " ('aren', 886),\n",
       " ('words', 884),\n",
       " ('miss', 882),\n",
       " ('tells', 881),\n",
       " ('entertainment', 879),\n",
       " ('local', 877),\n",
       " ('sequence', 875),\n",
       " ('rock', 875),\n",
       " ('bring', 869),\n",
       " ('beyond', 866),\n",
       " ('straight', 864),\n",
       " ('george', 864),\n",
       " ('oscar', 861),\n",
       " ('o', 859),\n",
       " ('upon', 859),\n",
       " ('whether', 856),\n",
       " ('romantic', 856),\n",
       " ('moving', 854),\n",
       " ('predictable', 854),\n",
       " ('sets', 852),\n",
       " ('similar', 852),\n",
       " ('review', 851),\n",
       " ('eye', 851),\n",
       " ('falls', 851),\n",
       " ('mystery', 850),\n",
       " ('lady', 848),\n",
       " ('richard', 846),\n",
       " ('talk', 842),\n",
       " ('enjoyable', 842),\n",
       " ('needs', 841),\n",
       " ('appears', 841),\n",
       " ('giving', 839),\n",
       " ('within', 832),\n",
       " ('message', 829),\n",
       " ('theater', 828),\n",
       " ('ten', 828),\n",
       " ('animation', 826),\n",
       " ('near', 824),\n",
       " ('team', 824),\n",
       " ('above', 819),\n",
       " ('sister', 818),\n",
       " ('red', 818),\n",
       " ('sequel', 818),\n",
       " ('theme', 816),\n",
       " ('dull', 816),\n",
       " ('nearly', 815),\n",
       " ('stand', 815),\n",
       " ('lee', 814),\n",
       " ('bunch', 813),\n",
       " ('points', 812),\n",
       " ('mention', 811),\n",
       " ('feels', 810),\n",
       " ('add', 810),\n",
       " ('york', 810),\n",
       " ('herself', 810),\n",
       " ('haven', 809),\n",
       " ('release', 807),\n",
       " ('ways', 804),\n",
       " ('storyline', 804),\n",
       " ('surprised', 802),\n",
       " ('easy', 802),\n",
       " ('using', 801),\n",
       " ('named', 800),\n",
       " ('fantastic', 797),\n",
       " ('begins', 796),\n",
       " ('lots', 796),\n",
       " ('working', 794),\n",
       " ('die', 794),\n",
       " ('actual', 793),\n",
       " ('effort', 792),\n",
       " ('feature', 791),\n",
       " ('tale', 789),\n",
       " ('french', 789),\n",
       " ('minute', 789),\n",
       " ('hate', 788),\n",
       " ('stay', 787),\n",
       " ('follow', 787),\n",
       " ('clear', 786),\n",
       " ('viewers', 786),\n",
       " ('tom', 784),\n",
       " ('elements', 783),\n",
       " ('among', 782),\n",
       " ('comments', 779),\n",
       " ('typical', 778),\n",
       " ('showing', 775),\n",
       " ('avoid', 775),\n",
       " ('editing', 775),\n",
       " ('season', 773),\n",
       " ('tried', 773),\n",
       " ('famous', 772),\n",
       " ('sorry', 771),\n",
       " ('fall', 770),\n",
       " ('check', 769),\n",
       " ('dialog', 769),\n",
       " ('peter', 768),\n",
       " ('period', 767),\n",
       " ('certain', 765),\n",
       " ('form', 765),\n",
       " ('soundtrack', 764),\n",
       " ('filmed', 764),\n",
       " ('buy', 764),\n",
       " ('general', 764),\n",
       " ('parents', 763),\n",
       " ('weak', 762),\n",
       " ('means', 761),\n",
       " ('material', 761),\n",
       " ('realistic', 758),\n",
       " ('figure', 758),\n",
       " ('somehow', 757),\n",
       " ('doubt', 757),\n",
       " ('crime', 757),\n",
       " ('space', 755),\n",
       " ('disney', 754),\n",
       " ('gone', 754),\n",
       " ('viewing', 750),\n",
       " ('kept', 750),\n",
       " ('leads', 749),\n",
       " ('th', 745),\n",
       " ('greatest', 745),\n",
       " ('dance', 744),\n",
       " ('lame', 742),\n",
       " ('suspense', 741),\n",
       " ('zombie', 740),\n",
       " ('third', 738),\n",
       " ('brought', 737),\n",
       " ('imagine', 736),\n",
       " ('atmosphere', 735),\n",
       " ('hear', 734),\n",
       " ('whatever', 732),\n",
       " ('particular', 730),\n",
       " ('de', 729),\n",
       " ('america', 728),\n",
       " ('sequences', 727),\n",
       " ('move', 726),\n",
       " ('indeed', 722),\n",
       " ('rent', 721),\n",
       " ('average', 720),\n",
       " ('eventually', 720),\n",
       " ('learn', 720),\n",
       " ('wait', 719),\n",
       " ('forget', 718),\n",
       " ('reviews', 718),\n",
       " ('note', 717),\n",
       " ('deal', 717),\n",
       " ('japanese', 716),\n",
       " ('surprise', 715),\n",
       " ('sexual', 714),\n",
       " ('poorly', 714),\n",
       " ('stage', 714),\n",
       " ('okay', 713),\n",
       " ('premise', 712),\n",
       " ('believable', 711),\n",
       " ('sit', 710),\n",
       " ('possibly', 709),\n",
       " ('subject', 709),\n",
       " ('nature', 709),\n",
       " ('decided', 705),\n",
       " ('expected', 704),\n",
       " ('truth', 700),\n",
       " ('dr', 700),\n",
       " ('imdb', 700),\n",
       " ('street', 699),\n",
       " ('became', 697),\n",
       " ('free', 697),\n",
       " ('difficult', 695),\n",
       " ('screenplay', 695),\n",
       " ('romance', 694),\n",
       " ('killing', 694),\n",
       " ('baby', 692),\n",
       " ('joe', 691),\n",
       " ('dog', 688),\n",
       " ('nor', 686),\n",
       " ('hot', 686),\n",
       " ('question', 685),\n",
       " ('reading', 685),\n",
       " ('leaves', 683),\n",
       " ('needed', 683),\n",
       " ('begin', 678),\n",
       " ('meets', 677),\n",
       " ('society', 676),\n",
       " ('directors', 676),\n",
       " ('unless', 675),\n",
       " ('credits', 673),\n",
       " ('superb', 671),\n",
       " ('shame', 671),\n",
       " ('otherwise', 671),\n",
       " ('write', 670),\n",
       " ('situation', 669),\n",
       " ('meet', 668),\n",
       " ('dramatic', 667),\n",
       " ('memorable', 666),\n",
       " ('male', 666),\n",
       " ('open', 665),\n",
       " ('weird', 663),\n",
       " ('dream', 663),\n",
       " ('writers', 663),\n",
       " ('badly', 663),\n",
       " ('earlier', 663),\n",
       " ('forced', 661),\n",
       " ('fi', 661),\n",
       " ('acted', 660),\n",
       " ('sci', 658),\n",
       " ('emotional', 657),\n",
       " ('jane', 657),\n",
       " ('laughs', 657),\n",
       " ('crazy', 657),\n",
       " ('older', 656),\n",
       " ('monster', 655),\n",
       " ('beauty', 655),\n",
       " ('realize', 654),\n",
       " ('comment', 653),\n",
       " ('deep', 652),\n",
       " ('footage', 651),\n",
       " ('interested', 651),\n",
       " ('forward', 651),\n",
       " ('fantasy', 648),\n",
       " ('ask', 648),\n",
       " ('plus', 645),\n",
       " ('whom', 645),\n",
       " ('mark', 645),\n",
       " ('sounds', 645),\n",
       " ('directing', 644),\n",
       " ('features', 642),\n",
       " ('keeps', 642),\n",
       " ('development', 642),\n",
       " ('mess', 641),\n",
       " ('quickly', 639),\n",
       " ('air', 639),\n",
       " ('box', 638),\n",
       " ('creepy', 638),\n",
       " ('perfectly', 637),\n",
       " ('girlfriend', 637),\n",
       " ('towards', 637),\n",
       " ('worked', 635),\n",
       " ('unique', 634),\n",
       " ('cheesy', 634),\n",
       " ('setting', 634),\n",
       " ('effect', 633),\n",
       " ('plenty', 632),\n",
       " ('bill', 632),\n",
       " ('hands', 632),\n",
       " ('total', 632),\n",
       " ('result', 631),\n",
       " ('brings', 630),\n",
       " ('fire', 630),\n",
       " ('previous', 630),\n",
       " ('personal', 629),\n",
       " ('incredibly', 628),\n",
       " ('rate', 626),\n",
       " ('business', 625),\n",
       " ('doctor', 624),\n",
       " ('joke', 624),\n",
       " ('christmas', 623),\n",
       " ('casting', 623),\n",
       " ('apart', 623),\n",
       " ('return', 623),\n",
       " ('e', 622),\n",
       " ('leading', 622),\n",
       " ('admit', 621),\n",
       " ('cop', 620),\n",
       " ('powerful', 620),\n",
       " ('appear', 620),\n",
       " ('background', 619),\n",
       " ('boys', 618),\n",
       " ('ben', 617),\n",
       " ('present', 616),\n",
       " ('meant', 615),\n",
       " ('era', 614),\n",
       " ('telling', 614),\n",
       " ('battle', 614),\n",
       " ('hardly', 613),\n",
       " ('break', 613),\n",
       " ('potential', 612),\n",
       " ('create', 612),\n",
       " ('masterpiece', 612),\n",
       " ('secret', 611),\n",
       " ('pay', 610),\n",
       " ('political', 609),\n",
       " ('gay', 608),\n",
       " ('fighting', 607),\n",
       " ('dumb', 607),\n",
       " ('twist', 606),\n",
       " ('fails', 606),\n",
       " ('various', 604),\n",
       " ('co', 602),\n",
       " ('portrayed', 601),\n",
       " ('villain', 600),\n",
       " ('inside', 600),\n",
       " ('western', 599),\n",
       " ('nudity', 598),\n",
       " ('outside', 598),\n",
       " ('william', 596),\n",
       " ('reasons', 596),\n",
       " ('front', 595),\n",
       " ('ideas', 595),\n",
       " ('match', 594),\n",
       " ('missing', 594),\n",
       " ('deserves', 591),\n",
       " ('married', 590),\n",
       " ('expecting', 588),\n",
       " ('rich', 587),\n",
       " ('fairly', 587),\n",
       " ('list', 586),\n",
       " ...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_counts.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's keep the first 10000 most frequent words. As Andrew noted, most of the words in the vocabulary are rarely used so they will have little effect on our predictions. Below, we'll sort `vocab` by the count value and keep the 10000 most frequent words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['like', 'there', 'her', 'or', 'just', 'about', 'out', 'if', 'has', 'what', 'some', 'good', 'can', 'more', 'she', 'when', 'very', 'up', 'time', 'no', 'even', 'my', 'would', 'which', 'story', 'only', 'really', 'see', 'their', 'had', 'we', 'were', 'me', 'well', 'than', 'much', 'get', 'bad', 'been', 'people', 'will', 'do', 'other', 'also', 'into', 'first', 'great', 'because', 'how', 'him', 'don', 'most', 'made', 'its', 'then', 'make', 'way', 'them', 'could', 'too']\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(total_counts, key=total_counts.get, reverse=True)[40:10040]\n",
    "print(vocab[:60])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the last word in our vocabulary? We can use this to judge if 10000 is too few. If the last word is pretty common, we probably need to keep more words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beef :  30\n"
     ]
    }
   ],
   "source": [
    "print(vocab[-1], ': ', total_counts[vocab[-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last word in our vocabulary shows up in 30 reviews out of 25000. I think it's fair to say this is a tiny proportion of reviews. We are probably fine with this number of words.\n",
    "\n",
    "**Note:** When you run, you may see a different word from the one shown above, but it will also have the value `30`. That's because there are many words tied for that number of counts, and the `Counter` class does not guarantee which one will be returned in the case of a tie.\n",
    "\n",
    "Now for each review in the data, we'll make a word vector. First we need to make a mapping of word to index, pretty easy to do with a dictionary comprehension.\n",
    "\n",
    "> **Exercise:** Create a dictionary called `word2idx` that maps each word in the vocabulary to an index. The first word in `vocab` has index `0`, the second word has index `1`, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'guevara': 7433,\n",
       " 'balls': 4524,\n",
       " 'downtown': 9008,\n",
       " 'magic': 1159,\n",
       " 'novak': 4753,\n",
       " 'species': 4379,\n",
       " 'slasher': 1110,\n",
       " 'nowhere': 1212,\n",
       " 'frequent': 4705,\n",
       " 'supposedly': 1447,\n",
       " 'davis': 1487,\n",
       " 'contributed': 6695,\n",
       " 'mobile': 6227,\n",
       " 'mockery': 8839,\n",
       " 'graphic': 2097,\n",
       " 'characterisation': 7157,\n",
       " 'secondly': 4042,\n",
       " 'language': 1034,\n",
       " 'misfire': 9605,\n",
       " 'prevalent': 9224,\n",
       " 'vintage': 6454,\n",
       " 'skull': 5109,\n",
       " 'busby': 7698,\n",
       " 'olympic': 9848,\n",
       " 'projected': 7461,\n",
       " 'upper': 2939,\n",
       " 'ustinov': 4898,\n",
       " 'nation': 2582,\n",
       " 'receives': 4880,\n",
       " 'nonsensical': 4965,\n",
       " 'lindsay': 5293,\n",
       " 'discovered': 1898,\n",
       " 'snuff': 6311,\n",
       " 'sacrificed': 9329,\n",
       " 'saif': 8946,\n",
       " 'creator': 4502,\n",
       " 'appreciate': 1084,\n",
       " 'farrell': 4639,\n",
       " 'priceless': 4762,\n",
       " 'existed': 3799,\n",
       " 'connie': 7993,\n",
       " 'necessary': 1607,\n",
       " 'moonstruck': 8561,\n",
       " 'theater': 691,\n",
       " 'stupidity': 2940,\n",
       " 'styles': 3782,\n",
       " 'fright': 6519,\n",
       " 'attacking': 6426,\n",
       " 'unnecessary': 1679,\n",
       " 'sensibility': 7220,\n",
       " 'wastes': 6879,\n",
       " 'dandy': 5746,\n",
       " 'alcoholism': 8742,\n",
       " 'action': 163,\n",
       " 'slow': 500,\n",
       " 'wheels': 9767,\n",
       " 'efforts': 1992,\n",
       " 'checked': 5045,\n",
       " 'academic': 8990,\n",
       " 'irrational': 8452,\n",
       " 'boys': 920,\n",
       " 'monday': 8185,\n",
       " 'gabriel': 4575,\n",
       " 'appreciation': 4669,\n",
       " 'goals': 6485,\n",
       " 'pity': 2172,\n",
       " 'escaping': 6384,\n",
       " 'dentist': 3026,\n",
       " 'echo': 8577,\n",
       " 'objective': 5102,\n",
       " 'toward': 1789,\n",
       " 'instance': 1776,\n",
       " 'claustrophobic': 5648,\n",
       " 'egypt': 7817,\n",
       " 'continuous': 8956,\n",
       " 'fiance': 6412,\n",
       " 'corporation': 6042,\n",
       " 'later': 260,\n",
       " 'suffered': 3056,\n",
       " 'youthful': 6122,\n",
       " 'honestly': 1187,\n",
       " 'trailers': 4155,\n",
       " 'officials': 8564,\n",
       " 'timed': 8047,\n",
       " 'something': 102,\n",
       " 'parade': 5133,\n",
       " 'slaves': 6584,\n",
       " 'fashion': 1539,\n",
       " 'applaud': 6043,\n",
       " 'rewarded': 7158,\n",
       " 'flop': 3963,\n",
       " 'college': 1100,\n",
       " 'jealous': 3612,\n",
       " 'land': 1456,\n",
       " 'directs': 4117,\n",
       " 'sullavan': 9789,\n",
       " 'barton': 8316,\n",
       " 'lt': 8366,\n",
       " 'gender': 4582,\n",
       " 'brothers': 994,\n",
       " 'norwegian': 9443,\n",
       " 'streets': 1889,\n",
       " 'mccarthy': 7054,\n",
       " 'comparing': 4364,\n",
       " 'dialogues': 3894,\n",
       " 'feel': 191,\n",
       " 'sheer': 2041,\n",
       " 'fooled': 4408,\n",
       " 'toby': 6395,\n",
       " 'mysteriously': 6787,\n",
       " 'marines': 8362,\n",
       " 'lousy': 2252,\n",
       " 'editor': 3640,\n",
       " 'dire': 3567,\n",
       " 'line': 302,\n",
       " 'milk': 5073,\n",
       " 'boost': 8631,\n",
       " 'blockbusters': 7305,\n",
       " 'standards': 1490,\n",
       " 'seven': 1477,\n",
       " 'worn': 4698,\n",
       " 'vivah': 9135,\n",
       " 'witnessing': 7405,\n",
       " 'wonderland': 6109,\n",
       " 'presentation': 2912,\n",
       " 'gershwin': 6703,\n",
       " 'stinker': 4161,\n",
       " 'gardner': 9504,\n",
       " 'hits': 1869,\n",
       " 'slows': 9181,\n",
       " 'muscular': 8845,\n",
       " 'shelf': 4108,\n",
       " 'planes': 6773,\n",
       " 'approach': 1425,\n",
       " 'booker': 8672,\n",
       " 'doom': 4602,\n",
       " 'interrupted': 7358,\n",
       " 'refuse': 5864,\n",
       " 'alba': 8131,\n",
       " 'phase': 6755,\n",
       " 'banks': 8048,\n",
       " 'hesitate': 9221,\n",
       " 'belly': 6270,\n",
       " 'limited': 1697,\n",
       " 'endless': 2130,\n",
       " 'wrenching': 6017,\n",
       " 'concludes': 8966,\n",
       " 'steps': 3118,\n",
       " 'tested': 8927,\n",
       " 'jet': 3496,\n",
       " 'mclaglen': 4889,\n",
       " 'culkin': 8186,\n",
       " 'number': 561,\n",
       " 'passive': 9029,\n",
       " 'kidman': 5435,\n",
       " 'slater': 7212,\n",
       " 'ambiguity': 7124,\n",
       " 'crawford': 4937,\n",
       " 'extraordinarily': 8554,\n",
       " 'rodriguez': 7265,\n",
       " 'gain': 3171,\n",
       " 'alec': 4991,\n",
       " 'saw': 177,\n",
       " 'preachy': 5546,\n",
       " 'california': 2532,\n",
       " 'letters': 4409,\n",
       " 'salesman': 6499,\n",
       " 'owe': 8619,\n",
       " 'mud': 7891,\n",
       " 'factual': 6945,\n",
       " 'deliberate': 6385,\n",
       " 'impossible': 1105,\n",
       " 'tormented': 6300,\n",
       " 'rave': 4948,\n",
       " 'dana': 4850,\n",
       " 'tierney': 5285,\n",
       " 'annoy': 7711,\n",
       " 'argument': 3676,\n",
       " 'flesh': 2045,\n",
       " 'anxious': 6886,\n",
       " 'students': 1460,\n",
       " 'matters': 2221,\n",
       " 'ounce': 9743,\n",
       " 'topped': 9466,\n",
       " 'colors': 2428,\n",
       " 'comics': 3344,\n",
       " 'sons': 3070,\n",
       " 'huston': 5826,\n",
       " 'bolivia': 9273,\n",
       " 'claiming': 5672,\n",
       " 'nonexistent': 8691,\n",
       " 'viewers': 735,\n",
       " 'concerns': 3222,\n",
       " 'caruso': 8579,\n",
       " 'detract': 6138,\n",
       " 'spoken': 2788,\n",
       " 'regrets': 9082,\n",
       " 'least': 180,\n",
       " 'drove': 5480,\n",
       " 'introduces': 4250,\n",
       " 'caroline': 9606,\n",
       " 'expert': 2704,\n",
       " 'firmly': 5884,\n",
       " 'brick': 8192,\n",
       " 'stripped': 9322,\n",
       " 'yea': 9802,\n",
       " 'jewish': 2858,\n",
       " 'yep': 6182,\n",
       " 'liz': 8711,\n",
       " 'pedestrian': 6753,\n",
       " 'griffith': 4170,\n",
       " 'possibilities': 4280,\n",
       " 'isolated': 4307,\n",
       " 'touched': 2775,\n",
       " 'fixed': 8422,\n",
       " 'soccer': 4198,\n",
       " 'hours': 581,\n",
       " 'landscapes': 4757,\n",
       " 'gap': 7056,\n",
       " 'secretly': 4489,\n",
       " 'compelling': 1383,\n",
       " 'pecker': 7462,\n",
       " 'hackman': 6083,\n",
       " 'term': 2808,\n",
       " 'towers': 5721,\n",
       " 'subject': 811,\n",
       " 'describe': 1577,\n",
       " 'ii': 1472,\n",
       " 'cell': 2696,\n",
       " 'mere': 2641,\n",
       " 'zenia': 9844,\n",
       " 'wwi': 9070,\n",
       " 'creek': 5920,\n",
       " 'towards': 889,\n",
       " 'firing': 5540,\n",
       " 'powerful': 917,\n",
       " 'julia': 2551,\n",
       " 'lyrical': 9159,\n",
       " 'empathize': 9319,\n",
       " 'threatening': 3476,\n",
       " 'man': 86,\n",
       " 'famous': 746,\n",
       " 'chuck': 3164,\n",
       " 'photo': 4770,\n",
       " 'parking': 6854,\n",
       " 'horribly': 2290,\n",
       " 'ledger': 8494,\n",
       " 'antics': 3812,\n",
       " 'uncomfortable': 3069,\n",
       " 'ya': 4120,\n",
       " 'flying': 1480,\n",
       " 'pin': 4881,\n",
       " 'releasing': 6912,\n",
       " 'student': 1369,\n",
       " 'wiped': 6731,\n",
       " 'exorcist': 6286,\n",
       " 'disappeared': 4265,\n",
       " 'shines': 3071,\n",
       " 'natalie': 5838,\n",
       " 'keeping': 1834,\n",
       " 'required': 2518,\n",
       " 'died': 1069,\n",
       " 'shaggy': 6942,\n",
       " 'plays': 257,\n",
       " 'durbin': 8879,\n",
       " 'banter': 6044,\n",
       " 'waits': 9160,\n",
       " 'alone': 533,\n",
       " 'spoof': 2762,\n",
       " 'puerto': 6243,\n",
       " 'reminds': 1732,\n",
       " 'hadley': 6539,\n",
       " 'elvis': 2999,\n",
       " 'recorded': 4077,\n",
       " 'brits': 9124,\n",
       " 'generation': 2126,\n",
       " 'access': 4500,\n",
       " 'married': 955,\n",
       " 'friendly': 2477,\n",
       " 'popular': 1005,\n",
       " 'own': 164,\n",
       " 'mel': 3647,\n",
       " 'tin': 8121,\n",
       " 'crippled': 6425,\n",
       " 'various': 940,\n",
       " 'billy': 1414,\n",
       " 'potter': 5954,\n",
       " 'pals': 8770,\n",
       " 'programming': 8102,\n",
       " 'drum': 7929,\n",
       " 'cameras': 3872,\n",
       " 'reasoning': 8226,\n",
       " 'downey': 5106,\n",
       " 'cares': 2189,\n",
       " 'guaranteed': 5436,\n",
       " 'persona': 3466,\n",
       " 'malone': 5018,\n",
       " 'fanning': 8555,\n",
       " 'aware': 1829,\n",
       " 'weren': 1111,\n",
       " 'forgets': 7581,\n",
       " 'wagner': 5160,\n",
       " 'graveyard': 6569,\n",
       " 'burial': 7598,\n",
       " 'change': 598,\n",
       " 'sarandon': 6609,\n",
       " 'explosive': 6831,\n",
       " 'gothic': 3298,\n",
       " 'investigation': 3407,\n",
       " 'advantage': 3013,\n",
       " 'winning': 1509,\n",
       " 'greatness': 5004,\n",
       " 'painted': 4142,\n",
       " 'horror': 148,\n",
       " 'tom': 736,\n",
       " 'reese': 8128,\n",
       " 'adventurous': 9330,\n",
       " 'neal': 7528,\n",
       " 'stadium': 7271,\n",
       " 'viggo': 9203,\n",
       " 'endure': 4264,\n",
       " 'strikingly': 9356,\n",
       " 'nicolas': 5491,\n",
       " 'didnt': 6594,\n",
       " 'rooting': 5988,\n",
       " 'biblical': 5885,\n",
       " 'push': 3539,\n",
       " 'guts': 3157,\n",
       " 'monstrous': 9446,\n",
       " 'neck': 3197,\n",
       " 'atlantis': 3887,\n",
       " 'frightening': 2463,\n",
       " 'brawl': 9930,\n",
       " 'energy': 1642,\n",
       " 'moody': 4287,\n",
       " 'parsons': 6098,\n",
       " 'aunt': 2754,\n",
       " 'orlando': 8395,\n",
       " 'technical': 1687,\n",
       " 'appearing': 3199,\n",
       " 'millennium': 8480,\n",
       " 'mindless': 2991,\n",
       " 'drugs': 1602,\n",
       " 'posing': 6792,\n",
       " 'mice': 6183,\n",
       " 'burn': 3447,\n",
       " 'melodramatic': 3595,\n",
       " 'horrors': 3520,\n",
       " 'hooked': 3230,\n",
       " 'malden': 8206,\n",
       " 'frances': 7053,\n",
       " 'armor': 8145,\n",
       " 'untrue': 9422,\n",
       " 'natali': 7159,\n",
       " 'pull': 1533,\n",
       " 'quarters': 9629,\n",
       " 'feinstone': 7213,\n",
       " 'noteworthy': 6897,\n",
       " 'deciding': 6900,\n",
       " 'diaz': 8314,\n",
       " 'visit': 1927,\n",
       " 'combat': 3919,\n",
       " 'goodbye': 6585,\n",
       " 'meteor': 6887,\n",
       " 'regarded': 5349,\n",
       " 'swept': 5773,\n",
       " 'sweet': 980,\n",
       " 'abu': 8231,\n",
       " 'laden': 6370,\n",
       " 'creatures': 2281,\n",
       " 'rating': 622,\n",
       " 'gloomy': 7248,\n",
       " 'suspect': 1710,\n",
       " 'singers': 5063,\n",
       " 'circa': 7855,\n",
       " 'collapse': 8165,\n",
       " 'customers': 7438,\n",
       " 'clothing': 3895,\n",
       " 'desk': 7710,\n",
       " 'spelled': 8049,\n",
       " 'begin': 834,\n",
       " 'august': 6528,\n",
       " 'anchorman': 9426,\n",
       " 'marty': 4640,\n",
       " 'ratio': 8556,\n",
       " 'surgeon': 8335,\n",
       " 'lots': 722,\n",
       " 'heads': 1763,\n",
       " 'relating': 7034,\n",
       " 'robbed': 7798,\n",
       " 'satirical': 5774,\n",
       " 'secret': 932,\n",
       " 'vincenzo': 7907,\n",
       " 'kills': 1039,\n",
       " 'charles': 1310,\n",
       " 'international': 1910,\n",
       " 'reagan': 7529,\n",
       " 'introduction': 2804,\n",
       " 'distract': 6500,\n",
       " 'faye': 7692,\n",
       " 'sets': 676,\n",
       " 'comfort': 5050,\n",
       " 'correctly': 4936,\n",
       " 'prefers': 8694,\n",
       " 'shock': 1385,\n",
       " 'corpses': 5362,\n",
       " 'unimaginative': 6229,\n",
       " 'cruelty': 5463,\n",
       " 'gave': 470,\n",
       " 'twins': 4981,\n",
       " 'underneath': 5155,\n",
       " 'outstanding': 1280,\n",
       " 'wrapped': 4509,\n",
       " 'despair': 4748,\n",
       " 'presence': 1305,\n",
       " 'dumber': 6642,\n",
       " 'currie': 9657,\n",
       " 'carries': 2860,\n",
       " 'mentality': 5629,\n",
       " 'split': 3150,\n",
       " 'groove': 8317,\n",
       " 'deal': 800,\n",
       " 'danning': 8974,\n",
       " 'props': 4063,\n",
       " 'labor': 5385,\n",
       " 'lou': 3533,\n",
       " 'beatty': 3813,\n",
       " 'randall': 7125,\n",
       " 'boobs': 8030,\n",
       " 'start': 334,\n",
       " 'second': 291,\n",
       " 'kung': 2070,\n",
       " 'r': 1309,\n",
       " 'bottom': 1262,\n",
       " 'ethnic': 5268,\n",
       " 'th': 774,\n",
       " 'strung': 7514,\n",
       " 'tempted': 5643,\n",
       " 'fodder': 7811,\n",
       " 'unbelievably': 3739,\n",
       " 'hark': 8841,\n",
       " 'flash': 3064,\n",
       " 'galaxy': 6151,\n",
       " 'backdrops': 9009,\n",
       " 'integrated': 9472,\n",
       " 'there': 1,\n",
       " 'tension': 1015,\n",
       " 'subtext': 6586,\n",
       " 'eleven': 5897,\n",
       " 'angelina': 7274,\n",
       " 'spade': 7521,\n",
       " 'visited': 5297,\n",
       " 'headed': 2789,\n",
       " 'grail': 9474,\n",
       " 'compliment': 6993,\n",
       " 'annoyance': 8071,\n",
       " 'filmed': 756,\n",
       " 'sat': 1751,\n",
       " 'cooper': 2830,\n",
       " 'writes': 4446,\n",
       " 'esther': 5232,\n",
       " 'accomplish': 5187,\n",
       " 'mistress': 4687,\n",
       " 'respectively': 5094,\n",
       " 'entirety': 6181,\n",
       " 'insists': 5609,\n",
       " 'needs': 686,\n",
       " 'being': 72,\n",
       " 'launched': 8558,\n",
       " 'greatest': 775,\n",
       " 'thank': 1217,\n",
       " 'henderson': 8427,\n",
       " 'eastern': 4882,\n",
       " 'upsetting': 9956,\n",
       " 'safely': 7301,\n",
       " 'rushed': 3247,\n",
       " 'camps': 9561,\n",
       " 'officers': 3976,\n",
       " 'haha': 9405,\n",
       " 'crying': 2506,\n",
       " 'whats': 4518,\n",
       " 'overnight': 9785,\n",
       " 'skits': 5322,\n",
       " 'philo': 7686,\n",
       " 'heroes': 1636,\n",
       " 'introducing': 6754,\n",
       " 'clues': 3549,\n",
       " 'prisoners': 4619,\n",
       " 'wan': 8134,\n",
       " 'visitor': 7406,\n",
       " 'chest': 4497,\n",
       " 'open': 849,\n",
       " 'stairs': 5621,\n",
       " 'goer': 9556,\n",
       " 'tsui': 8453,\n",
       " 'quote': 3125,\n",
       " 'saddest': 9191,\n",
       " 'carter': 3043,\n",
       " 'ghastly': 7843,\n",
       " 'keitel': 8823,\n",
       " 'turturro': 9892,\n",
       " 'anchors': 8368,\n",
       " 'red': 698,\n",
       " 'rudd': 8599,\n",
       " 'force': 1066,\n",
       " 'rushes': 9414,\n",
       " 'godfather': 3330,\n",
       " 'scores': 4565,\n",
       " 'interpret': 9331,\n",
       " 'village': 1985,\n",
       " 'stirring': 8259,\n",
       " 'convince': 2446,\n",
       " 'crashed': 8003,\n",
       " 'hilarity': 5727,\n",
       " 'era': 924,\n",
       " 'strictly': 3405,\n",
       " 'theory': 2492,\n",
       " 'tv': 203,\n",
       " 'proceed': 7687,\n",
       " 'teenagers': 2267,\n",
       " 'sees': 1027,\n",
       " 'wholly': 4951,\n",
       " 'has': 8,\n",
       " 'running': 570,\n",
       " 'none': 551,\n",
       " 'everyone': 256,\n",
       " 'veterans': 7194,\n",
       " 'pile': 2351,\n",
       " 'varying': 8298,\n",
       " 'welcomed': 8961,\n",
       " 'festivals': 7042,\n",
       " 'respective': 5379,\n",
       " 'employed': 5570,\n",
       " 'main': 251,\n",
       " 'affecting': 7713,\n",
       " 'stage': 805,\n",
       " 'garden': 3928,\n",
       " 'hundreds': 3037,\n",
       " 'beatles': 5358,\n",
       " 'preminger': 5363,\n",
       " 'liberty': 8107,\n",
       " 'fuller': 4915,\n",
       " 'almost': 178,\n",
       " 'dressing': 4749,\n",
       " 'glenn': 3690,\n",
       " 'heroine': 1768,\n",
       " 'deemed': 7510,\n",
       " 'adult': 1071,\n",
       " 'arkin': 6716,\n",
       " 'sea': 1919,\n",
       " 'pathos': 6816,\n",
       " 'sitting': 1201,\n",
       " 'anger': 2495,\n",
       " 'fondness': 9979,\n",
       " 'animators': 8771,\n",
       " 'masked': 7285,\n",
       " 'unbearable': 3741,\n",
       " 'love': 76,\n",
       " 'paying': 2601,\n",
       " 'revolt': 6455,\n",
       " 'pet': 2829,\n",
       " 'clumsy': 4026,\n",
       " 'lions': 8318,\n",
       " 'rubbish': 1843,\n",
       " 'subsequently': 7576,\n",
       " 'acclaim': 8063,\n",
       " 'shake': 4382,\n",
       " 'craft': 3821,\n",
       " 'fest': 3275,\n",
       " 'mystery': 681,\n",
       " 'excels': 7666,\n",
       " 'amount': 1103,\n",
       " 'wisely': 6326,\n",
       " 'scoop': 5679,\n",
       " 'preston': 5027,\n",
       " 'abused': 5180,\n",
       " 'below': 1844,\n",
       " 'frame': 2048,\n",
       " 'wizard': 4404,\n",
       " 'aired': 3111,\n",
       " 'rockets': 8292,\n",
       " 'unfair': 5048,\n",
       " 'crash': 2416,\n",
       " 'stale': 4726,\n",
       " 'vera': 6923,\n",
       " 'solo': 4214,\n",
       " 'steven': 2081,\n",
       " 'safe': 2197,\n",
       " 'intact': 6865,\n",
       " 'toned': 6989,\n",
       " 'skipped': 9849,\n",
       " 'pete': 5049,\n",
       " 'craven': 3691,\n",
       " 'getting': 351,\n",
       " 'subtleties': 9274,\n",
       " 'unless': 838,\n",
       " 'threats': 9659,\n",
       " 'apologies': 9468,\n",
       " 'where': 79,\n",
       " 'challenging': 4678,\n",
       " 'ish': 5188,\n",
       " 'tossed': 6161,\n",
       " 'numbing': 6352,\n",
       " 'routine': 2412,\n",
       " 'figure': 764,\n",
       " 'hold': 1012,\n",
       " 'room': 615,\n",
       " 'debut': 1944,\n",
       " 'parent': 3665,\n",
       " 'fired': 3332,\n",
       " 'repulsive': 6086,\n",
       " 'except': 501,\n",
       " 'passing': 2501,\n",
       " 'hammerhead': 8774,\n",
       " 'tiresome': 4482,\n",
       " 'jovi': 9682,\n",
       " 'john': 258,\n",
       " 'theo': 8858,\n",
       " 'walked': 2466,\n",
       " 'highly': 495,\n",
       " 'madly': 9893,\n",
       " 'pay': 933,\n",
       " 'eccentric': 3924,\n",
       " 'downward': 9922,\n",
       " 'drawings': 8064,\n",
       " 'charlotte': 4283,\n",
       " 'extremely': 525,\n",
       " 'party': 1004,\n",
       " 'police': 516,\n",
       " 'clockwork': 8586,\n",
       " 'nd': 3135,\n",
       " 'gable': 5944,\n",
       " 'talk': 684,\n",
       " 'temper': 7727,\n",
       " 'animals': 1311,\n",
       " 'families': 2096,\n",
       " 'gamera': 6479,\n",
       " 'space': 768,\n",
       " 'integrity': 4952,\n",
       " 'incredible': 990,\n",
       " 'zane': 5597,\n",
       " 'records': 5556,\n",
       " 'collar': 7413,\n",
       " 'raping': 9771,\n",
       " 'convincing': 1019,\n",
       " 'coke': 6774,\n",
       " 'galactica': 6980,\n",
       " 'agenda': 5167,\n",
       " 'ted': 2438,\n",
       " 'swiss': 8218,\n",
       " 'although': 217,\n",
       " 'trains': 6717,\n",
       " 'numerous': 1885,\n",
       " 'animation': 693,\n",
       " 'excuses': 6732,\n",
       " 'tackle': 8120,\n",
       " 'psychological': 1911,\n",
       " 'blockbuster': 2572,\n",
       " 'besides': 1306,\n",
       " 'involve': 4266,\n",
       " 'barbarian': 8925,\n",
       " 'lumet': 4223,\n",
       " 'assassination': 5794,\n",
       " 'watered': 8939,\n",
       " 'accent': 1128,\n",
       " 'surgery': 5737,\n",
       " 'dumbest': 6866,\n",
       " 'gratuitous': 2105,\n",
       " 'boyfriend': 1346,\n",
       " 'sticking': 6312,\n",
       " 'unravel': 8034,\n",
       " 'lang': 6632,\n",
       " 'originality': 2767,\n",
       " 'toole': 8312,\n",
       " 'terry': 3881,\n",
       " 'severe': 4302,\n",
       " 'intrusive': 9931,\n",
       " 'li': 3868,\n",
       " 'allegedly': 9469,\n",
       " 'longtime': 9366,\n",
       " 'cast': 138,\n",
       " 'antonioni': 4966,\n",
       " 'enters': 3366,\n",
       " 'search': 1726,\n",
       " 'gallery': 7009,\n",
       " 'martha': 5382,\n",
       " 'polished': 4810,\n",
       " 'bunny': 5140,\n",
       " 'edison': 7018,\n",
       " 'background': 919,\n",
       " 'incest': 7304,\n",
       " 'circle': 4114,\n",
       " 'forrest': 7968,\n",
       " 'array': 7382,\n",
       " 'affleck': 5786,\n",
       " 'several': 408,\n",
       " 'bursts': 9267,\n",
       " 'sandra': 4308,\n",
       " 'executive': 3352,\n",
       " 'charisma': 3257,\n",
       " 'resort': 4651,\n",
       " 'information': 1564,\n",
       " 'bills': 8464,\n",
       " 'supplies': 9614,\n",
       " 'hands': 897,\n",
       " 'centers': 4538,\n",
       " 'drew': 2056,\n",
       " 'posh': 8549,\n",
       " 'contribution': 6060,\n",
       " 'seats': 7043,\n",
       " 'senior': 6316,\n",
       " 'lars': 8273,\n",
       " 'flicks': 1479,\n",
       " 'dreaming': 7555,\n",
       " 'accents': 2390,\n",
       " 'through': 106,\n",
       " 'popcorn': 3869,\n",
       " 'representation': 5602,\n",
       " 'fallon': 6791,\n",
       " 'standard': 1205,\n",
       " 'eggs': 9487,\n",
       " 'age': 504,\n",
       " 'occur': 3858,\n",
       " 'evolved': 9232,\n",
       " 'briefly': 3293,\n",
       " 'teeth': 2640,\n",
       " 'failed': 1136,\n",
       " 'manic': 8153,\n",
       " 'disguise': 5528,\n",
       " 'crowd': 2204,\n",
       " 'ghetto': 6655,\n",
       " 'turning': 1526,\n",
       " 'dealt': 3267,\n",
       " 'swing': 5295,\n",
       " 'garland': 6212,\n",
       " 'gore': 542,\n",
       " 'pigs': 7964,\n",
       " 'taut': 7668,\n",
       " 'hostage': 7314,\n",
       " 'relentlessly': 6712,\n",
       " 'sleep': 1604,\n",
       " 'blaine': 9293,\n",
       " 'every': 136,\n",
       " 'strangely': 2810,\n",
       " 'invisible': 2422,\n",
       " 'dave': 3699,\n",
       " 'fetched': 4107,\n",
       " 'frontier': 6413,\n",
       " 'overwhelmed': 9065,\n",
       " 'wes': 3608,\n",
       " 'here': 88,\n",
       " 'arizona': 9162,\n",
       " 'peak': 5028,\n",
       " 'about': 5,\n",
       " 'alien': 1420,\n",
       " 'engaging': 1658,\n",
       " 'happening': 1389,\n",
       " 'together': 252,\n",
       " 'thought': 156,\n",
       " 'cowardly': 8429,\n",
       " 'apple': 7105,\n",
       " 'clark': 2382,\n",
       " 'bo': 2968,\n",
       " 'locations': 1928,\n",
       " 'primarily': 4094,\n",
       " 'alice': 2425,\n",
       " 'paperhouse': 9506,\n",
       " 'scooby': 3294,\n",
       " 'enhance': 6676,\n",
       " 'literally': 1163,\n",
       " 'pepper': 8188,\n",
       " 'colleague': 7530,\n",
       " 'regularly': 6844,\n",
       " 'mrs': 1947,\n",
       " 'idiocy': 8695,\n",
       " 'basinger': 5129,\n",
       " 'sober': 7908,\n",
       " 'accepted': 3151,\n",
       " 'appearances': 3248,\n",
       " 'intense': 1527,\n",
       " 'bio': 8274,\n",
       " 'industry': 1525,\n",
       " 'purchased': 4568,\n",
       " 'spoilers': 971,\n",
       " 'positives': 9908,\n",
       " 'respectable': 6248,\n",
       " 'greater': 2726,\n",
       " 'jerky': 8490,\n",
       " 'neutral': 9731,\n",
       " 'because': 47,\n",
       " 'ago': 548,\n",
       " 'demonstrated': 6617,\n",
       " 'stella': 6540,\n",
       " 'tolkien': 8675,\n",
       " 'praised': 5434,\n",
       " 'happily': 3034,\n",
       " 'branch': 9071,\n",
       " 'hang': 3160,\n",
       " 'justin': 4655,\n",
       " 'melbourne': 7722,\n",
       " 'adore': 6353,\n",
       " 'seeking': 2905,\n",
       " 'insanely': 9438,\n",
       " 'capacity': 7164,\n",
       " 'seemingly': 1511,\n",
       " 'invented': 5035,\n",
       " 'apes': 3827,\n",
       " 'form': 754,\n",
       " 'dialogs': 3181,\n",
       " 'enterprise': 4075,\n",
       " 'lombard': 9463,\n",
       " 'floors': 9495,\n",
       " 'manipulative': 4662,\n",
       " 'unaware': 4925,\n",
       " 'amazed': 2603,\n",
       " 'typically': 3399,\n",
       " 'olsen': 7242,\n",
       " 'files': 5022,\n",
       " 'cambodia': 9507,\n",
       " 'dedicated': 4243,\n",
       " 'mm': 4481,\n",
       " 'steal': 2040,\n",
       " 'miller': 2785,\n",
       " 'counterparts': 8132,\n",
       " 'stunningly': 6094,\n",
       " 'denzel': 3203,\n",
       " 'revealed': 1973,\n",
       " 'hideous': 4121,\n",
       " 'instances': 6892,\n",
       " 'cliched': 6785,\n",
       " 'forgotten': 1491,\n",
       " 'member': 1589,\n",
       " 'ewan': 9593,\n",
       " 'grudge': 5498,\n",
       " 'partial': 9282,\n",
       " 'folk': 3743,\n",
       " 'patricia': 5383,\n",
       " 'seat': 2154,\n",
       " 'ended': 995,\n",
       " 'roles': 506,\n",
       " 'spotted': 8294,\n",
       " 'blame': 1771,\n",
       " 'kazan': 5902,\n",
       " 'lincoln': 2694,\n",
       " 'noble': 3004,\n",
       " 'thinner': 9335,\n",
       " 'diverse': 6719,\n",
       " 'stereotypical': 2688,\n",
       " 'display': 2374,\n",
       " 'rehash': 7126,\n",
       " 'fighter': 3864,\n",
       " 'activities': 4916,\n",
       " 'engine': 7421,\n",
       " 'farm': 3766,\n",
       " 'figures': 2509,\n",
       " 'hopeful': 8951,\n",
       " 'separation': 9895,\n",
       " 'baddie': 8329,\n",
       " 'cant': 2214,\n",
       " 'efficient': 8761,\n",
       " 'park': 1426,\n",
       " 'transplant': 8240,\n",
       " 'casual': 5601,\n",
       " 'admits': 7520,\n",
       " 'feels': 708,\n",
       " 'load': 3748,\n",
       " 'nauseating': 7334,\n",
       " 'outer': 4103,\n",
       " 'vibrant': 5689,\n",
       " 'wagon': 9960,\n",
       " 'repeats': 7414,\n",
       " 'credibility': 2992,\n",
       " 'hate': 731,\n",
       " 'romanian': 8491,\n",
       " 'uninteresting': 2429,\n",
       " 'symbol': 6789,\n",
       " 'ham': 4842,\n",
       " 'pumbaa': 6340,\n",
       " 'racial': 4237,\n",
       " 'chairman': 9643,\n",
       " 'area': 1556,\n",
       " 'window': 1974,\n",
       " 'thereby': 7518,\n",
       " 'ego': 3436,\n",
       " 'homosexuality': 6120,\n",
       " 'streak': 9384,\n",
       " 'anime': 2085,\n",
       " 'kriemhild': 9229,\n",
       " 'boris': 5965,\n",
       " 'dragon': 2579,\n",
       " 'butler': 4727,\n",
       " 'fair': 1189,\n",
       " 'plodding': 7085,\n",
       " 'guns': 1801,\n",
       " 'latest': 2413,\n",
       " 'miniseries': 6004,\n",
       " 'tomatoes': 4680,\n",
       " 'tooth': 4771,\n",
       " 'grating': 8115,\n",
       " 'flames': 6943,\n",
       " 'warrior': 3639,\n",
       " 'journalist': 3849,\n",
       " 'vibe': 8050,\n",
       " 'examined': 8882,\n",
       " 'place': 230,\n",
       " 'explosion': 3835,\n",
       " 'importance': 3325,\n",
       " 'plus': 874,\n",
       " 'concerning': 3763,\n",
       " 'michaels': 8741,\n",
       " 'peaks': 8436,\n",
       " 'european': 1804,\n",
       " 'satire': 1939,\n",
       " 'stereotype': 4293,\n",
       " 'frenchman': 9710,\n",
       " 'bathroom': 3801,\n",
       " 'tear': 3263,\n",
       " 'universal': 2271,\n",
       " 'features': 879,\n",
       " 'camera': 323,\n",
       " 'vance': 5079,\n",
       " 'priests': 8848,\n",
       " 'collection': 1531,\n",
       " 'consist': 6906,\n",
       " 'flawless': 3501,\n",
       " 'exclusively': 7058,\n",
       " 'trusted': 8601,\n",
       " 'produce': 2175,\n",
       " 'porn': 1441,\n",
       " 'wished': 4383,\n",
       " 'vile': 5878,\n",
       " 'nuclear': 3408,\n",
       " 'answer': 1468,\n",
       " 'organized': 5707,\n",
       " 'actresses': 1433,\n",
       " 'far': 188,\n",
       " 'em': 2927,\n",
       " 'unconvincing': 2576,\n",
       " 'toni': 6191,\n",
       " 'flag': 7335,\n",
       " 'idealistic': 7977,\n",
       " 'askey': 9233,\n",
       " 'sneak': 4848,\n",
       " 'nightmare': 1637,\n",
       " 'wrap': 4706,\n",
       " 'adventure': 1077,\n",
       " 'fleshed': 6554,\n",
       " 'business': 906,\n",
       " 'basement': 3174,\n",
       " 'commentary': 1633,\n",
       " 'takes': 263,\n",
       " 'june': 4606,\n",
       " 'principles': 7918,\n",
       " 'grade': 1177,\n",
       " 'written': 352,\n",
       " 'sickness': 7683,\n",
       " 'trash': 1089,\n",
       " 'when': 15,\n",
       " 'barely': 1137,\n",
       " 'speeches': 5927,\n",
       " 'abomination': 7982,\n",
       " 'committed': 2461,\n",
       " 'euro': 8325,\n",
       " 'minimal': 3648,\n",
       " 'wellington': 9377,\n",
       " 'snappy': 9372,\n",
       " 'stages': 5502,\n",
       " 'homeless': 3224,\n",
       " 'rochester': 2977,\n",
       " 'theres': 8517,\n",
       " 'abruptly': 6099,\n",
       " 'worth': 249,\n",
       " 'incompetent': 4712,\n",
       " 'plan': 1266,\n",
       " 'duty': 4034,\n",
       " 'minutes': 190,\n",
       " 'proud': 2552,\n",
       " 'asleep': 2292,\n",
       " 'realistically': 7062,\n",
       " 'baffled': 9803,\n",
       " 'your': 90,\n",
       " 'immigrant': 6756,\n",
       " 'europa': 5645,\n",
       " 'politically': 4029,\n",
       " 'spider': 4717,\n",
       " 'garde': 8502,\n",
       " 'noises': 5175,\n",
       " 'experiences': 2418,\n",
       " 'adultery': 8300,\n",
       " 'fabric': 8216,\n",
       " 'relationship': 592,\n",
       " 'portraying': 2199,\n",
       " 'caron': 6266,\n",
       " 'niro': 4210,\n",
       " 'financial': 4057,\n",
       " 'whereas': 3066,\n",
       " 'payoff': 7229,\n",
       " 'jodie': 6302,\n",
       " 'wallach': 9711,\n",
       " 'ww': 4791,\n",
       " ...}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create the word-to-index dictionary here\n",
    "word2idx = {}\n",
    "for i,word in enumerate(vocab):\n",
    "    word2idx[word] = i\n",
    "word2idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text to vector function\n",
    "\n",
    "Now we can write a function that converts a some text to a word vector. The function will take a string of words as input and return a vector with the words counted up. Here's the general algorithm to do this:\n",
    "\n",
    "* Initialize the word vector with [np.zeros](https://docs.scipy.org/doc/numpy/reference/generated/numpy.zeros.html), it should be the length of the vocabulary.\n",
    "* Split the input string of text into a list of words with `.split(' ')`. Again, if you call `.split()` instead, you'll get slightly different results than what we show here.\n",
    "* For each word in that list, increment the element in the index associated with that word, which you get from `word2idx`.\n",
    "\n",
    "**Note:** Since all words aren't in the `vocab` dictionary, you'll get a key error if you run into one of those words. You can use the `.get` method of the `word2idx` dictionary to specify a default returned value when you make a key error. For example, `word2idx.get(word, None)` returns `None` if `word` doesn't exist in the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def text_to_vector(text):\n",
    "    text2vector = np.zeros((len(vocab)))\n",
    "    for word in text.split(' '):\n",
    "        if(word2idx.get(word, None) != None):\n",
    "            text2vector[word2idx[word]] = 1\n",
    "    return np.array(text2vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you do this right, the following code should return\n",
    "\n",
    "```\n",
    "text_to_vector('The tea is for a party to celebrate '\n",
    "               'the movie so she has no time for a cake')[:65]\n",
    "                   \n",
    "array([0, 1, 0, 0, 2, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0])\n",
    "```       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,\n",
       "        0.,  1.,  0.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_vector('The tea is for a party to celebrate the movie so she has no time for a cake')[:65]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, run through our entire review data set and convert each review to a word vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_vectors = np.zeros((len(reviews), len(vocab)), dtype=np.int_)\n",
    "for ii, (_, text) in enumerate(reviews.iterrows()):\n",
    "    word_vectors[ii] = text_to_vector(text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1],\n",
       "       [1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing out the first 5 word vectors\n",
    "word_vectors[:5, :23]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Validation, Test sets\n",
    "\n",
    "Now that we have the word_vectors, we're ready to split our data into train, validation, and test sets. Remember that we train on the train data, use the validation data to set the hyperparameters, and at the very end measure the network performance on the test data. Here we're using the function `to_categorical` from TFLearn to reshape the target data so that we'll have two output units and can classify with a softmax activation function. We actually won't be creating the validation set here, TFLearn will do that for us later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y = (labels=='positive').astype(np.int_)\n",
    "records = len(labels)\n",
    "\n",
    "shuffle = np.arange(records)\n",
    "np.random.shuffle(shuffle)\n",
    "test_fraction = 0.9\n",
    "\n",
    "train_split, test_split = shuffle[:int(records*test_fraction)], shuffle[int(records*test_fraction):]\n",
    "trainX, trainY = word_vectors[train_split,:], to_categorical(Y.values[train_split], 2)\n",
    "testX, testY = word_vectors[test_split,:], to_categorical(Y.values[test_split], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       ..., \n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the network\n",
    "\n",
    "[TFLearn](http://tflearn.org/) lets you build the network by [defining the layers](http://tflearn.org/layers/core/). \n",
    "\n",
    "### Input layer\n",
    "\n",
    "For the input layer, you just need to tell it how many units you have. For example, \n",
    "\n",
    "```\n",
    "net = tflearn.input_data([None, 100])\n",
    "```\n",
    "\n",
    "would create a network with 100 input units. The first element in the list, `None` in this case, sets the batch size. Setting it to `None` here leaves it at the default batch size.\n",
    "\n",
    "The number of inputs to your network needs to match the size of your data. For this example, we're using 10000 element long vectors to encode our input data, so we need 10000 input units.\n",
    "\n",
    "\n",
    "### Adding layers\n",
    "\n",
    "To add new hidden layers, you use \n",
    "\n",
    "```\n",
    "net = tflearn.fully_connected(net, n_units, activation='ReLU')\n",
    "```\n",
    "\n",
    "This adds a fully connected layer where every unit in the previous layer is connected to every unit in this layer. The first argument `net` is the network you created in the `tflearn.input_data` call. It's telling the network to use the output of the previous layer as the input to this layer. You can set the number of units in the layer with `n_units`, and set the activation function with the `activation` keyword. You can keep adding layers to your network by repeated calling `net = tflearn.fully_connected(net, n_units)`.\n",
    "\n",
    "### Output layer\n",
    "\n",
    "The last layer you add is used as the output layer. There for, you need to set the number of units to match the target data. In this case we are predicting two classes, positive or negative sentiment. You also need to set the activation function so it's appropriate for your model. Again, we're trying to predict if some input data belongs to one of two classes, so we should use softmax.\n",
    "\n",
    "```\n",
    "net = tflearn.fully_connected(net, 2, activation='softmax')\n",
    "```\n",
    "\n",
    "### Training\n",
    "To set how you train the network, use \n",
    "\n",
    "```\n",
    "net = tflearn.regression(net, optimizer='sgd', learning_rate=0.1, loss='categorical_crossentropy')\n",
    "```\n",
    "\n",
    "Again, this is passing in the network you've been building. The keywords: \n",
    "\n",
    "* `optimizer` sets the training method, here stochastic gradient descent\n",
    "* `learning_rate` is the learning rate\n",
    "* `loss` determines how the network error is calculated. In this example, with the categorical cross-entropy.\n",
    "\n",
    "Finally you put all this together to create the model with `tflearn.DNN(net)`. So it ends up looking something like \n",
    "\n",
    "```\n",
    "net = tflearn.input_data([None, 10])                          # Input\n",
    "net = tflearn.fully_connected(net, 5, activation='ReLU')      # Hidden\n",
    "net = tflearn.fully_connected(net, 2, activation='softmax')   # Output\n",
    "net = tflearn.regression(net, optimizer='sgd', learning_rate=0.1, loss='categorical_crossentropy')\n",
    "model = tflearn.DNN(net)\n",
    "```\n",
    "\n",
    "> **Exercise:** Below in the `build_model()` function, you'll put together the network using TFLearn. You get to choose how many layers to use, how many hidden units, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Network building\n",
    "def build_model():\n",
    "    # This resets all parameters and variables, leave this here\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    # Inputs\n",
    "    net = tflearn.input_data([None, 10000])\n",
    "\n",
    "    # Hidden layer(s)\n",
    "    net = tflearn.fully_connected(net, 200, activation='ReLU')\n",
    "    net = tflearn.fully_connected(net, 25, activation='ReLU')\n",
    "\n",
    "    # Output layer\n",
    "    net = tflearn.fully_connected(net, 2, activation='softmax')\n",
    "    net = tflearn.regression(net, optimizer='sgd', \n",
    "                             learning_rate=0.1, \n",
    "                             loss='categorical_crossentropy')\n",
    "    \n",
    "    model = tflearn.DNN(net)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intializing the model\n",
    "\n",
    "Next we need to call the `build_model()` function to actually build the model. In my solution I haven't included any arguments to the function, but you can add arguments so you can change parameters in the model if you want.\n",
    "\n",
    "> **Note:** You might get a bunch of warnings here. TFLearn uses a lot of deprecated code in TensorFlow. Hopefully it gets updated to the new TensorFlow version soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the network\n",
    "\n",
    "Now that we've constructed the network, saved as the variable `model`, we can fit it to the data. Here we use the `model.fit` method. You pass in the training features `trainX` and the training targets `trainY`. Below I set `validation_set=0.1` which reserves 10% of the data set as the validation set. You can also set the batch size and number of epochs with the `batch_size` and `n_epoch` keywords, respectively. Below is the code to fit our the network to our word vectors.\n",
    "\n",
    "You can rerun `model.fit` to train the network further if you think you can increase the validation accuracy. Remember, all hyperparameter adjustments must be done using the validation set. **Only use the test set after you're completely done training the network.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1589  | total loss: \u001b[1m\u001b[32m0.15089\u001b[0m\u001b[0m | time: 8.536s\n",
      "| SGD | epoch: 010 | loss: 0.15089 - acc: 0.9608 -- iter: 20224/20250\n",
      "Training Step: 1590  | total loss: \u001b[1m\u001b[32m0.15025\u001b[0m\u001b[0m | time: 9.595s\n",
      "| SGD | epoch: 010 | loss: 0.15025 - acc: 0.9585 | val_loss: 0.36265 - val_acc: 0.8644 -- iter: 20250/20250\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "model.fit(trainX, trainY, validation_set=0.1, show_metric=True, batch_size=128, n_epoch=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "After you're satisified with your hyperparameters, you can run the network on the test set to measure it's performance. Remember, *only do this after finalizing the hyperparameters*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.866\n"
     ]
    }
   ],
   "source": [
    "predictions = (np.array(model.predict(testX))[:,0] >= 0.5).astype(np.int_)\n",
    "test_accuracy = np.mean(predictions == testY[:,0], axis=0)\n",
    "print(\"Test accuracy: \", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try out your own text!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Helper function that uses your model to predict sentiment\n",
    "def test_sentence(sentence):\n",
    "    positive_prob = model.predict([text_to_vector(sentence.lower())])[0][1]\n",
    "    print('Sentence: {}'.format(sentence))\n",
    "    print('P(positive) = {:.3f} :'.format(positive_prob), \n",
    "          'Positive' if positive_prob > 0.5 else 'Negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: the movie was bad\n",
      "P(positive) = 0.238 : Negative\n",
      "Sentence: very good marvelous fantastic\n",
      "P(positive) = 0.888 : Positive\n"
     ]
    }
   ],
   "source": [
    "sentence = \"the movie was bad\"\n",
    "test_sentence(sentence)\n",
    "\n",
    "sentence = \"very good marvelous fantastic\"\n",
    "test_sentence(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
